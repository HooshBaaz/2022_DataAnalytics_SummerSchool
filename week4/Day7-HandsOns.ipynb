{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/logo3.png\" width=\"200\" height=\"200\" >\n",
    "\n",
    "<div style=\"display:block\"><br><br>\n",
    "    <div style=\"display:block\" align=left display=block> \n",
    "        <font size=5><b>Day7 - HandsOns - Classification</b></font><br>\n",
    "        <hr/>\n",
    "\n",
    "</div>\n",
    "\n",
    "<pre>\n",
    ".\n",
    "├── Importing Modules/Libraries\n",
    "│\n",
    "├── Data Cleaning\n",
    "│\n",
    "├── Train/Test split\n",
    "│ \n",
    "├── Classification using regression\n",
    "│ \n",
    "├── Dimensionality Reduction\n",
    "│\n",
    "├── Over-Sampling\n",
    "│\n",
    "├── Training Classifiers\n",
    "│\n",
    "└── Test your Model and Report results\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E-commerce is a huge business sector that allows customers to access a variety of goods and services with a few clicks. Many popular shopping platforms such as Amazon or Alibaba process millions of transactions annually. In recent years, due to the corona disease, online shopping has increased dramatically, therefore, the online shopping market has become very competitive and it is important for strong and innovative online shopping platforms.   \n",
    "One possible way to increase online shopping transactions is to understand and respond to customers' behavior. According to sufficient online shopping data and machine learning techniques, it is possible to determine the purchase intention of website visitors, so in this exercise, we want to use machine learning algorithms in Marketing Analytics, which is one of the topics discussed in recent years. let's get to know each other more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing anything, we need to get familiar with Dataset. The desired dataset is located in the `customers_intention.csv` file. This dataset contains various information related to customer behavior on online shopping websites, which helps us to perform marketing analysis and understand related KPIs and metrics. This dataset contains feature vectors belonging to 12330 sessions, in the sense that each row shows the behavior of a customer to buy a product and has a total of 10 numerical features and 8 categorical features. In the table below, a general explanation of the features of the dataset is given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Description |\n",
    "| :- | :- |\n",
    "| \"Administrative\", \"Administrative Duration\", \"Informational\", \"Informational Duration\", \"Product Related ,\"Product Related\", Duration\" | These features show the number of different types of pages visited by the visitor in that session and the total time spent in each of these page categories. The values of these features are taken from the URL information of the pages that the user visits and are updated simultaneously when the user performs an action.\n",
    "| \"Bounce Rate\", \"Exit Rate\" , \"Page Value\" | It shows the metrics measured by Google Analytics for each page on the e-commerce site. \"Bounce Rate\" feature for a web page, in percent Refers to visitors who enter the site and then leave the site without making any request (Bounce). The \"Exit Rate\" feature shows the percentage of visitors to a page who leave the site for another website. The \"Page Value\" attribute represents the average value of a web page that a user visited before completing an e-commerce transaction\n",
    "| \"Special Day\" | It indicates the closeness of the site visit time to a specific day (for example, Mother's Day, Valentine's Day) in which the session is most likely to be finalized with a transaction.\n",
    "| \"Month\", \"Browser\", \"Region\", \"Traffic type\", \" \"(as returning or new visitor), \"Weekend\" | It gives us information including month, browser type, region, type of traffic, type of players (new or old) and whether the purchase was made over the weekend.\n",
    "| \"Revenue\" | Indicates whether the visitor has made a purchase or not. Use the \"Revenue\" property as the class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this section, what you have to do is as follows:\n",
    " - read the dataset\n",
    " - print information of the dataset\n",
    " - plot number of data for each label in `Revenue` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of data for each class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after reading the data, it is time to clean the data. At this stage, we need to do the necessary pre-processing to clean the dataset. Some of the things we suggest you do are as follows:\n",
    "- Identification of null values\n",
    "- Handling the null values of each column in an appropriate way\n",
    "- one-hot encoding of categorical columns. you can use this [link](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) for one-hot encoding\n",
    "And any pre-processing you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and handle nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical encoding and one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "- Divide the data into two parts, train and test. Assign `80%` of the data to the train section.\n",
    "    - split in a `stratified` fashion. (Hint: you need to change a parameter in the corresponding method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train test split from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Using Regression\n",
    "\n",
    "- Assign +1 to every instance of customer visit that led to a purchase and assign -1 to every visit that did not lead to a purchase.\n",
    "- Using a regression model (univariate, multivariate, linear, polynomial, etc.), predict whether a cutomer's visit will lead to a purchase or not.\n",
    "- How do you decide whether a visit will lead to a purchase based on the output of the model which is a real-valued number? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension. Working in high-dimensional spaces can be undesirable for many reasons; raw data are often sparse as a consequence of the curse of dimensionality, and analyzing the data is usually computationally intractable (hard to control or deal with)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "in this section you ar goinig to:\n",
    "- plot datapoints in 2 dimensions using PCA\n",
    "- Choose the best number of dimensions for PCA by plotting `cumulative explained variance ratio`\n",
    "- Apply pca to the dataset with the number of dimensions you obtained in the previous section\n",
    "\n",
    "*`don't remember you to standardize data before PCA transformation!`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot datapoints in 2 dimensions using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best number of dimensions for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalanced classification involves developing predictive models on classification datasets that have a severe class imbalance.\n",
    "\n",
    "The challenge of working with imbalanced datasets is that most machine learning techniques will ignore, and in turn have poor performance on, the minority class, although typically it is performance on the minority class that is most important.\n",
    "\n",
    "One approach to addressing imbalanced datasets is to oversample the minority class. The simplest approach involves duplicating examples in the minority class, although these examples don’t add any new information to the model. Instead, new examples can be synthesized from the existing examples. This is a type of data augmentation for the minority class and is referred to as the Synthetic Minority Oversampling Technique, or SMOTE for short.\n",
    "\n",
    "in this section you are going to use `SMOTE` method for over-sampling data to get equal number of data for each data. After applying SMOTE plot number of data for each class again to see the diffrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libriary for SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of data for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is the process of predicting the class of given data points. Classes are sometimes called as targets/ labels or categories. Classification predictive modeling is the task of approximating a mapping function (f) from input variables (X) to discrete output variables (y).\n",
    "\n",
    "in this section you are going to train several cllassifiers like:\n",
    "- `SVM`\n",
    "- `KNN`\n",
    "- `Logistic Regression`\n",
    "- `Decision Tree`\n",
    "\n",
    "Use the dimensionally reduced `train` data to train the specified classifiers. \n",
    "- for each classifier use `gridsearch` to find best hyper parameters.\n",
    "    - use `cross validation` for grid search\n",
    "- after finding best parameters for each classifier, use them to train a classifier with founded parameters.\n",
    "    - again train your best classifiers with `cross valdiation`\n",
    "- use a bar plot to show each classifier's `accuracy`, `precision`, `f1` and `roc_auc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot for scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your Model and Report results\n",
    "\n",
    "choose the best model from last section based on the evalutiona metrics and bar plots and after that train the best classifier based on train data and test it's performance on test data. With this, we can see how good the model is on unseen data.\n",
    "\n",
    "- print `classification report` and plot `confusion matrix` based on your model's predictions and the real labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the best model again and evaluate it on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [over-smapling](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)\n",
    "- [classification](https://towardsdatascience.com/machine-learning-classifiers-a5cc4e1b0623)\n",
    "- [dimensionality reduction (Wikipedia)](https://en.wikipedia.org/wiki/Dimensionality_reduction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
